# dataset generation from `convml_tt`

Datasets for `convml_tt` can be generated by describing a "data-source", which
in a unified way allows for the ingestion of data from different sources. As
well as defining the "source" and "type" of your data-source, you can define
the domain and time-span over which to sample data, the number and size of any
triplets you wish to generate and the sampling resolution. These parameters are
all defined through a single `meta.yaml`-file which describes the entire
dataset. An example of a complete configuration-file is given below:

```yaml
source: goes16
type: truecolor_rgb

time:
  t_start: 2020-02-02T14:00
  t_end: 2020-02-02T14:30

domain:
  central_latitude: 13.3 # 13 + (18 / 60)
  central_longitude: -57.72 # -(57 + (43 / 60))
  l_zonal: 200000
  l_meridional: 200000

sampling:
  triplets:
    scene_collections_splitting: random_by_relative_sample_size
    N_triplets: {train: 10, study: 2}
    tile_N: 256
    tile_size: 200000.0
  rect:
    dx: 1000.0
```

## The `source` and `type` of your dataset

The first step is to define the `source` and `type`, currently `source ==
[goes16, les]` are supported. 

`source == goes16` will automatically fetch
GOES-16 data from Amazon S3 and with `type==truecolor_rgb` will generate
truecolor RGB composites from the first three radiance channels. has been
implemented.

`source == les` is intended to be used for working with data from Large-Eddy
Simulations. In this case any files residing in `source_data/les` be used to
generate scenes. The `scene_id` is generated by using the time-coordinate
(assumed to be named `time`) of the  data. `type` in this case simply refers to
the name of the variable in the datasets that will be used (support for
multi-channel datasets will be added in future)

Producing triplets for training and study:


## The timespan of your data-source

In the `time` section of `meta.yaml` you can define the timespan over which you
want to use data. In case of data from the `goes16` source this will be used
both for fetching the correct data and generating scene IDs from this data.
When using a `les` source this will simply filter scenes from the netCDF files
found. This section can be omitted for `les` source data, but not for `goes16`
data.

The timespan can be simply defined using `t_start` and `t_end`

```yaml
time:
  t_start: 2020-02-02T14:00
  t_end: 2020-02-02T14:30
```

You can use multiple intervals:

```yaml
time:
  intervals:
    - t_start: 2018-10-01 00:00:00
      t_end: 2019-03-01 00:00:00
    - t_start: 2019-10-01 00:00:00
      t_end: 2020-03-01 00:00:00
    - t_start: 2020-10-01 00:00:00
      t_end: 2021-03-01 00:00:00
  filters:
    N_hours_from_zenith: 4.0
```

And you may optionally list filters to use to exclude times within your defined
interval(s):

```yaml
time:
  t_start: 2020-02-02T14:00
  t_end: 2020-02-02T14:30
  filters:
    N_hours_from_zenith: 4.0
```


## The sampling `domain` for your data-source

The `domain` section of `meta.yaml` defines the spatial domain within which you
want to use data. Currently, all data is resampled onto a isometric Cartesian
grid (by setting `kind == rect`), in the case of `goes16` data (which is
natively on the lat/lon grid of the Earth's surface) this is done by doing a
projection onto a tangential plane centered on a point you define.

TODO: this hasn't been completed for LES data yet

```yaml
domain:
  kind: rect
  central_latitude: 14.0
  central_longitude: -48.0
  l_zonal: 3000.0e+3
  l_meridional: 1000.0e+3
```


## Sampling triplets and the entire domain

To do the tile-based embedding projections using `convml_tt` we must either
feed it individual tiles. There is currently implemented support for producing
triplets of tiles for this purpose or regridding the entire domain at a fixed
resolution and feeding data using a sliding-window to generate tiles at
inference time.

```yaml
sampling:
  triplets:
    scene_collections_splitting: random_by_relative_sample_size
    N_triplets: {train: 10, study: 2}
    tile_N: 256
    tile_size: 200000.0
  rect:
    dx: 1000.0
```

## Auxiliary data

For some source (for example `goes16`) there may be auxiliary data fields that
you would like to download and regrid to use during inference time. You should list the ones you wish to download using the `aux_products` part of the `meta.yaml` file:

```yaml
aux_products:
  - ACHA
```

# Processing pipeline

To facilitate generating huge datasets and processing all data in parallel the
production of datasets for convml_tt has been implement using the
[luigi](https://luigi.readthedocs.io/) pipeline package by creating individual
luigi `Task`s. Each of these tasks serve a different purpose and the ones you
are most likely to use will be described below. You can also read the source
code yourself in `convml_tt.data.sources.pipeline`.

## Generating scene IDs

```bash
$> python -m luigi --module convml_tt.data.sources.pipeline GenerateSceneIDs
```

## Generate cropped data for all scenes

```bash
luigi --module convml_tt.data.sources.pipeline GenerateCroppedScenes
luigi --module convml_tt.data.sources.pipeline GenerateCroppedScenes --aux-product ACHA
```

## Generate tiles

```bash
luigi --module convml_tt.data.sources.pipeline GenerateTiles
```

## Generate regridded data for all scenes

```bash
luigi --module convml_tt.data.sources.pipeline GenerateRegriddedScenes
luigi --module convml_tt.data.sources.pipeline GenerateRegriddedScenes --aux-product ACHA
```

## Plotting optical flow trajectories for all scenes

```bash
$> python -m luigi --module convml_tt.interpretation.rectpred.pipeline.flow PlotAllScenesWithScenePrefixTrajectories
```

## Sliding-window based inference

```bash
luigi --module convml_tt.data.interpretation.rectpred.pipeline AggregateFullDatasetImagePredictionMapData
```
